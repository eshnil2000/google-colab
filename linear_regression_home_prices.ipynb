{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_home_prices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshnil2000/google-colab/blob/master/linear_regression_home_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XrB-CXTqbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.5\n",
        "training_epochs = 30\n",
        "display_step = 1\n",
        "batch_size=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWe3Vm7qgsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "9e80eade-d6b1-4bde-e13b-3e0c17acc1f3"
      },
      "source": [
        "!git clone https://github.com/eshnil2000/google-colab.git\n",
        "%cd google-colab\n",
        "#Install required modules\n",
        "!pip install tensorflow numpy matplotlib pandas sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'google-colab'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (269/269), 30.15 MiB | 41.11 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/google-colab\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MKuyXHGqhSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/housepricedata.csv')\n",
        "dataset = df.values\n",
        "train_X = dataset[:,0:10]\n",
        "train_Y = dataset[:,10]\n",
        "n_batches = int(train_X.shape[0]/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTPEu0tuqjqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(train_X)\n",
        "train_X=X_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfdHh2f6qlo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth=len(np.unique(train_Y))\n",
        "indices=train_Y\n",
        "onehot_Y=tf.one_hot(indices, depth)\n",
        "with tf.Session() as sess:\n",
        "    onehot_Y=sess.run(onehot_Y)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldnzaDaqn32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "4dc51ec7-7b6c-4124-c988-a836cb7e1018"
      },
      "source": [
        "# Run optimization and test\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "optim_history=[]\n",
        "\n",
        "X = tf.placeholder(tf.float32,shape=(batch_size,10), name=\"input\")\n",
        "Y = tf.placeholder(tf.float32,shape=(batch_size,2), name=\"label\")\n",
        "# Set model weights\n",
        "# Create weights and bias\n",
        "w = tf.Variable(tf.random_normal(shape=(10,2), stddev=0.1), name=\"weights\")\n",
        "b = tf.Variable(tf.zeros(shape=(1,2)), name='bias')\n",
        "\n",
        "# calculate scores\n",
        "logits = tf.matmul(X, w)+b\n",
        "\n",
        "# Entropy cost function and loss\n",
        "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y)\n",
        "loss = tf.reduce_mean(entropy)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "#optimizer= tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "gd_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(entropy)\n",
        "\n",
        "correct_mask = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
        "\n",
        "iterations = len(train_Y*training_epochs)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "data_X, data_Y = iterator.get_next()\n",
        "data_Y = tf.cast(data_Y, tf.int32)\n",
        "\n",
        "c1=[]\n",
        "\n",
        "\n",
        "with tf.Session() as sess, tqdm(total = iterations) as pbar:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    try:\n",
        "      while True:\n",
        "        sess.run(gd_step, feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "        pbar.update(batch_size)\n",
        "\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      pass\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "  dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  data_X, data_Y = iterator.get_next()\n",
        "  data_Y = tf.cast(data_Y, tf.int32)\n",
        "  try:\n",
        "    while True:\n",
        "      ans = sess.run(accuracy, feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "  except tf.errors.OutOfRangeError:\n",
        "    pass\n",
        "  print(\"Accuracy: {:.4}%\".format(ans*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 11:38:37.649054 139691475015552 deprecation.py:323] From <ipython-input-6-9188ca0805bb>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0727 11:38:37.802829 139691475015552 deprecation.py:323] From <ipython-input-6-9188ca0805bb>:32: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "21888it [00:00, 22413.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 51.56%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJhAzuF18AAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}