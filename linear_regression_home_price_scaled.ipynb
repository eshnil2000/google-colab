{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eshnil2000/google-colab/blob/master/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (1.16.1)\n",
      "Requirement already satisfied: matplotlib in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: pandas in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: sklearn in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.16.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from sklearn) (0.21.2)\n",
      "Requirement already satisfied: setuptools in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: h5py in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda3/envs/python3.7-eth-tf/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "#Install required modules\n",
    "!pip install tensorflow numpy matplotlib pandas sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 3\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/housepricedata.csv')\n",
    "dataset = df.values\n",
    "train_X = dataset[:,0:10]\n",
    "train_Y = dataset[:,10]\n",
    "batch_size=64\n",
    "n_batches = int(train_X.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(train_X)\n",
    "train_X=X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=len(np.unique(train_Y))\n",
    "indices=train_Y\n",
    "onehot_Y=tf.one_hot(indices, depth)\n",
    "with tf.Session() as sess:\n",
    "    onehot_Y=sess.run(onehot_Y)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(tf.float32,shape=(batch_size,10), name=\"input\")\n",
    "Y = tf.placeholder(tf.float32,shape=(batch_size,2), name=\"label\")\n",
    "\n",
    "# Set model weights\n",
    "# Create weights and bias\n",
    "w = tf.Variable(tf.random_normal(shape=(10,1), stddev=0.01), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros(shape=(1,2)), name='bias')\n",
    "\n",
    "# calculate scores\n",
    "logits = tf.matmul(X, w) + b\n",
    "\n",
    "# Entropy cost function and loss\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=logits\n",
    "cost=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init  = tf.global_variables_initializer()\n",
    "init2 = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define the function that feeds the data to the model .\n",
    "def train_input_fn(x_train,y_train,batch_size=64):\n",
    "    ##Here we are using dataset API.\n",
    "    '''\n",
    "    take the data from tensor_slices i.e. an array of data-points in simple words.\n",
    "    '''\n",
    "    dataset =    tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(batch_size) \n",
    "    dataset_iterator = dataset.make_one_shot_iterator()   \n",
    "    return dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization and test\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(init2)\n",
    "    #tf.train.start_queue_runners(sess)\n",
    "\n",
    "    #sess.run(train_Y)\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        #for (x, y) in zip(train_X, train_Y):\n",
    "        #for (x, y) in zip(train_X, onehot_Y): \n",
    "        for i in range(n_batches):\n",
    "            slicex, slicey=train_input_fn(train_X,onehot_Y)\n",
    "            sess.run(optimizer, feed_dict={X: slicex.eval(), Y: slicey.eval()})\n",
    "            #sess.run(optimizer, feed_dict={X: x.reshape(1,10), Y: y.reshape(1,2)})\n",
    "            \n",
    "            _, loss_value = sess.run([optimizer, loss], feed_dict={X: slicex.eval(), Y: slicey.eval()})\n",
    "        loss_history.append(loss_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6930591, 0.69299155, 0.6929419]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.3767123287671233\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(init2)\n",
    "    total_correct_preds = 0\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        slicex, slicey=train_input_fn(train_X,onehot_Y)\n",
    "        logits_batch = sess.run(logits, feed_dict={X: slicex.eval(), Y: slicey.eval()})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(slicey.eval(), 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "        \n",
    "    print(\"Test accuracy is {0}\".format(total_correct_preds/train_X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
