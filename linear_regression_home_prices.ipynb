{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_home_prices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshnil2000/google-colab/blob/master/linear_regression_home_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XrB-CXTqbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.1\n",
        "training_epochs = 30\n",
        "display_step = 1\n",
        "batch_size=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWe3Vm7qgsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install required modules\n",
        "#Install and import all required modules\n",
        "#%%capture\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "!git clone https://github.com/eshnil2000/google-colab.git\n",
        "%cd google-colab\n",
        "#Install required modules\n",
        "!pip install tensorflow numpy matplotlib pandas sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MKuyXHGqhSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/housepricedata.csv')\n",
        "dataset = df.values\n",
        "train_X = dataset[:,0:10]\n",
        "train_Y = dataset[:,10]\n",
        "n_batches = int(train_X.shape[0]/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTPEu0tuqjqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(train_X)\n",
        "train_X=X_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfdHh2f6qlo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth=len(np.unique(train_Y))\n",
        "indices=train_Y\n",
        "onehot_Y=tf.one_hot(indices, depth)\n",
        "with tf.Session() as sess:\n",
        "    onehot_Y=sess.run(onehot_Y)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldnzaDaqn32",
        "colab_type": "code",
        "outputId": "ebff4c49-d696-4c68-b1a6-8078b235f918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Run optimization and test\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "optim_history=[]\n",
        "\n",
        "X = tf.placeholder(tf.float32,shape=(batch_size,10), name=\"input\")\n",
        "Y = tf.placeholder(tf.float32,shape=(batch_size,2), name=\"label\")\n",
        "# Set model weights\n",
        "# Create weights and bias\n",
        "w = tf.Variable(tf.random_normal(shape=(10,2), stddev=0.1), name=\"weights\")\n",
        "b = tf.Variable(tf.zeros(shape=(1,2)), name='bias')\n",
        "\n",
        "# calculate scores\n",
        "logits = tf.matmul(X, w)+b\n",
        "\n",
        "# Entropy cost function and loss\n",
        "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y)\n",
        "loss = tf.reduce_mean(entropy)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "#optimizer= tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "gd_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(entropy)\n",
        "\n",
        "correct_mask = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
        "\n",
        "iterations = len(train_Y*training_epochs)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "data_X, data_Y = iterator.get_next()\n",
        "data_Y = tf.cast(data_Y, tf.int32)\n",
        "\n",
        "c1=[]\n",
        "\n",
        "\n",
        "with tf.Session() as sess, tqdm(total = iterations) as pbar:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    try:\n",
        "      while True:\n",
        "        sess.run(gd_step, feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "        pbar.update(batch_size)\n",
        "\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      pass\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "  dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  data_X, data_Y = iterator.get_next()\n",
        "  data_Y = tf.cast(data_Y, tf.int32)\n",
        "  try:\n",
        "    while True:\n",
        "      ans = sess.run(accuracy, feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "  except tf.errors.OutOfRangeError:\n",
        "    pass\n",
        "  print(\"\\n Accuracy: {:.4}%\".format(ans*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21888it [00:01, 19353.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Accuracy: 54.69%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJhAzuF18AAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
