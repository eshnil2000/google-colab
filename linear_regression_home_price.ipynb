{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshnil2000/google-colab/blob/master/linear_regression_home_price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XrB-CXTqbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.6\n",
        "training_epochs = 25\n",
        "display_step = 1\n",
        "batch_size=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWe3Vm7qgsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "745706cc-42b8-481a-c50e-41863a4e9af8"
      },
      "source": [
        "!git clone https://github.com/eshnil2000/google-colab.git\n",
        "%cd google-colab\n",
        "#Install required modules\n",
        "!pip install tensorflow numpy matplotlib pandas sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'google-colab'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/112)   \u001b[K\rremote: Counting objects:   1% (2/112)   \u001b[K\rremote: Counting objects:   2% (3/112)   \u001b[K\rremote: Counting objects:   3% (4/112)   \u001b[K\rremote: Counting objects:   4% (5/112)   \u001b[K\rremote: Counting objects:   5% (6/112)   \u001b[K\rremote: Counting objects:   6% (7/112)   \u001b[K\rremote: Counting objects:   7% (8/112)   \u001b[K\rremote: Counting objects:   8% (9/112)   \u001b[K\rremote: Counting objects:   9% (11/112)   \u001b[K\rremote: Counting objects:  10% (12/112)   \u001b[K\rremote: Counting objects:  11% (13/112)   \u001b[K\rremote: Counting objects:  12% (14/112)   \u001b[K\rremote: Counting objects:  13% (15/112)   \u001b[K\rremote: Counting objects:  14% (16/112)   \u001b[K\rremote: Counting objects:  15% (17/112)   \u001b[K\rremote: Counting objects:  16% (18/112)   \u001b[K\rremote: Counting objects:  17% (20/112)   \u001b[K\rremote: Counting objects:  18% (21/112)   \u001b[K\rremote: Counting objects:  19% (22/112)   \u001b[K\rremote: Counting objects:  20% (23/112)   \u001b[K\rremote: Counting objects:  21% (24/112)   \u001b[K\rremote: Counting objects:  22% (25/112)   \u001b[K\rremote: Counting objects:  23% (26/112)   \u001b[K\rremote: Counting objects:  24% (27/112)   \u001b[K\rremote: Counting objects:  25% (28/112)   \u001b[K\rremote: Counting objects:  26% (30/112)   \u001b[K\rremote: Counting objects:  27% (31/112)   \u001b[K\rremote: Counting objects:  28% (32/112)   \u001b[K\rremote: Counting objects:  29% (33/112)   \u001b[K\rremote: Counting objects:  30% (34/112)   \u001b[K\rremote: Counting objects:  31% (35/112)   \u001b[K\rremote: Counting objects:  32% (36/112)   \u001b[K\rremote: Counting objects:  33% (37/112)   \u001b[K\rremote: Counting objects:  34% (39/112)   \u001b[K\rremote: Counting objects:  35% (40/112)   \u001b[K\rremote: Counting objects:  36% (41/112)   \u001b[K\rremote: Counting objects:  37% (42/112)   \u001b[K\rremote: Counting objects:  38% (43/112)   \u001b[K\rremote: Counting objects:  39% (44/112)   \u001b[K\rremote: Counting objects:  40% (45/112)   \u001b[K\rremote: Counting objects:  41% (46/112)   \u001b[K\rremote: Counting objects:  42% (48/112)   \u001b[K\rremote: Counting objects:  43% (49/112)   \u001b[K\rremote: Counting objects:  44% (50/112)   \u001b[K\rremote: Counting objects:  45% (51/112)   \u001b[K\rremote: Counting objects:  46% (52/112)   \u001b[K\rremote: Counting objects:  47% (53/112)   \u001b[K\rremote: Counting objects:  48% (54/112)   \u001b[K\rremote: Counting objects:  49% (55/112)   \u001b[K\rremote: Counting objects:  50% (56/112)   \u001b[K\rremote: Counting objects:  51% (58/112)   \u001b[K\rremote: Counting objects:  52% (59/112)   \u001b[K\rremote: Counting objects:  53% (60/112)   \u001b[K\rremote: Counting objects:  54% (61/112)   \u001b[K\rremote: Counting objects:  55% (62/112)   \u001b[K\rremote: Counting objects:  56% (63/112)   \u001b[K\rremote: Counting objects:  57% (64/112)   \u001b[K\rremote: Counting objects:  58% (65/112)   \u001b[K\rremote: Counting objects:  59% (67/112)   \u001b[K\rremote: Counting objects:  60% (68/112)   \u001b[K\rremote: Counting objects:  61% (69/112)   \u001b[K\rremote: Counting objects:  62% (70/112)   \u001b[K\rremote: Counting objects:  63% (71/112)   \u001b[K\rremote: Counting objects:  64% (72/112)   \u001b[K\rremote: Counting objects:  65% (73/112)   \u001b[K\rremote: Counting objects:  66% (74/112)   \u001b[K\rremote: Counting objects:  67% (76/112)   \u001b[K\rremote: Counting objects:  68% (77/112)   \u001b[K\rremote: Counting objects:  69% (78/112)   \u001b[K\rremote: Counting objects:  70% (79/112)   \u001b[K\rremote: Counting objects:  71% (80/112)   \u001b[K\rremote: Counting objects:  72% (81/112)   \u001b[K\rremote: Counting objects:  73% (82/112)   \u001b[K\rremote: Counting objects:  74% (83/112)   \u001b[K\rremote: Counting objects:  75% (84/112)   \u001b[K\rremote: Counting objects:  76% (86/112)   \u001b[K\rremote: Counting objects:  77% (87/112)   \u001b[K\rremote: Counting objects:  78% (88/112)   \u001b[K\rremote: Counting objects:  79% (89/112)   \u001b[K\rremote: Counting objects:  80% (90/112)   \u001b[K\rremote: Counting objects:  81% (91/112)   \u001b[K\rremote: Counting objects:  82% (92/112)   \u001b[K\rremote: Counting objects:  83% (93/112)   \u001b[K\rremote: Counting objects:  84% (95/112)   \u001b[K\rremote: Counting objects:  85% (96/112)   \u001b[K\rremote: Counting objects:  86% (97/112)   \u001b[K\rremote: Counting objects:  87% (98/112)   \u001b[K\rremote: Counting objects:  88% (99/112)   \u001b[K\rremote: Counting objects:  89% (100/112)   \u001b[K\rremote: Counting objects:  90% (101/112)   \u001b[K\rremote: Counting objects:  91% (102/112)   \u001b[K\rremote: Counting objects:  92% (104/112)   \u001b[K\rremote: Counting objects:  93% (105/112)   \u001b[K\rremote: Counting objects:  94% (106/112)   \u001b[K\rremote: Counting objects:  95% (107/112)   \u001b[K\rremote: Counting objects:  96% (108/112)   \u001b[K\rremote: Counting objects:  97% (109/112)   \u001b[K\rremote: Counting objects:  98% (110/112)   \u001b[K\rremote: Counting objects:  99% (111/112)   \u001b[K\rremote: Counting objects: 100% (112/112)   \u001b[K\rremote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 259 (delta 53), reused 27 (delta 9), pack-reused 147\u001b[K\n",
            "Receiving objects: 100% (259/259), 30.32 MiB | 32.48 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "/content/google-colab/google-colab/google-colab\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MKuyXHGqhSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/housepricedata.csv')\n",
        "dataset = df.values\n",
        "train_X = dataset[:,0:10]\n",
        "train_Y = dataset[:,10]\n",
        "n_batches = int(train_X.shape[0]/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTPEu0tuqjqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(train_X)\n",
        "train_X=X_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfdHh2f6qlo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth=len(np.unique(train_Y))\n",
        "indices=train_Y\n",
        "onehot_Y=tf.one_hot(indices, depth)\n",
        "with tf.Session() as sess:\n",
        "    onehot_Y=sess.run(onehot_Y)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldnzaDaqn32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae9ca05d-4d08-4458-b4ee-352288feb6d8"
      },
      "source": [
        "# Run optimization and test\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "optim_history=[]\n",
        "\n",
        "X = tf.placeholder(tf.float32,shape=(batch_size,10), name=\"input\")\n",
        "Y = tf.placeholder(tf.float32,shape=(batch_size,2), name=\"label\")\n",
        "# Set model weights\n",
        "# Create weights and bias\n",
        "w = tf.Variable(tf.random_normal(shape=(10,2), stddev=0.1), name=\"weights\")\n",
        "b = tf.Variable(tf.zeros(shape=(1,2)), name='bias')\n",
        "\n",
        "# calculate scores\n",
        "logits = tf.matmul(X, w)+b\n",
        "\n",
        "# Entropy cost function and loss\n",
        "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y)\n",
        "loss = tf.reduce_mean(entropy)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "iterations = len(train_Y*training_epochs)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "data_X, data_Y = iterator.get_next()\n",
        "data_Y = tf.cast(data_Y, tf.int32)\n",
        "\n",
        "c1=[]\n",
        "\n",
        "with tf.Session() as sess, tqdm(total = iterations) as pbar:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    for i in range(n_batches-1):\n",
        "      try:\n",
        "        while True:\n",
        "\n",
        "          _, loss_value = sess.run([optimizer, loss], feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "\n",
        "          loss_history.append(loss_value)\n",
        "          pbar.update(batch_size)\n",
        "          loss_history.append(loss_value)\n",
        "          optim_history.append(optim_value)\n",
        "      except tf.errors.OutOfRangeError:\n",
        "        pass"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18240it [00:02, 8382.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8c7fMnuvNPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "459cb5ec-7830-457f-dee2-e2b826005a2d"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_X, onehot_Y))\n",
        "dataset = dataset.repeat(training_epochs).batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "data_X, data_Y = iterator.get_next()\n",
        "data_Y = tf.cast(data_Y, tf.int32)\n",
        "\n",
        "# Prediction\n",
        "with tf.Session() as sess, tqdm(total = len(onehot_Y)) as pbar:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  total_correct_preds = 0\n",
        "  for i in range(n_batches):\n",
        "    logits_batch = sess.run(logits, feed_dict={X: data_X.eval(), Y: data_Y.eval()})\n",
        "    preds = tf.nn.softmax(logits_batch)\n",
        "    correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(data_Y.eval(), 1))\n",
        "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
        "    total_correct_preds += sess.run(accuracy)\n",
        "    pbar.update(batch_size)\n",
        "\n",
        "print(\"Test accuracy is {0}\".format(total_correct_preds/train_X.shape[0]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1408/1460 [00:14<00:00, 103.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.47534246575342465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7XQlB093XPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}